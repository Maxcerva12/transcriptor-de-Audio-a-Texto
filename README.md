# ğŸ™ï¸ transcriptor

**Transcriptor de audio a texto gratuito usando OpenAI Whisper**

Una aplicaciÃ³n web completa que permite transcribir archivos de audio a texto de forma gratuita, perfecta para estudiantes, investigadores y profesionales que necesiten convertir grabaciones de reuniones, conferencias o entrevistas a texto.

## ğŸš€ CaracterÃ­sticas

- âœ… **TranscripciÃ³n precisa** con modelos Whisper de OpenAI
- âœ… **MÃºltiples formatos** de audio soportados (MP3, WAV, FLAC, M4A, OGG, WMA, AAC)
- âœ… **Interfaz drag & drop** intuitiva y moderna
- âœ… **6 modelos diferentes** para equilibrar velocidad y calidad
- âœ… **DetecciÃ³n automÃ¡tica** de idioma
- âœ… **TraducciÃ³n** al inglÃ©s disponible
- âœ… **Descarga de resultados** en texto plano
- âœ… **Segmentos detallados** con timestamps
- âœ… **Totalmente gratuito** y open source

## ğŸ—ï¸ Arquitectura

- **Frontend**: Next.js 15 + React 18 + TypeScript + Tailwind CSS
- **Backend**: FastAPI + Python + OpenAI Whisper
- **TranscripciÃ³n**: OpenAI Whisper (modelos tiny, base, small, medium, large, turbo)

## ğŸ“‹ Prerrequisitos

- **Node.js** 18 o superior
- **Python** 3.8 o superior
- **FFmpeg** (para procesamiento de audio)

### Instalar FFmpeg en Windows:

```powershell
# Con Chocolatey
choco install ffmpeg

# Con Scoop
scoop install ffmpeg
```

## ğŸš€ InstalaciÃ³n Completa

### 1. Clonar el proyecto

```bash
cd c:\Users\tu_usuario\tu_carpeta
# El proyecto ya estÃ¡ en transcriptor/
```

### 2. Configurar Backend

```bash
cd c:\backend

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual (Windows)
.\venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Iniciar servidor
python run.py
```

El backend estarÃ¡ disponible en: http://localhost:8000

### 3. Configurar Frontend

```bash
cd c:\frontend

# Instalar dependencias
npm install

# Iniciar aplicaciÃ³n
npm run dev
```

La aplicaciÃ³n estarÃ¡ disponible en: http://localhost:3000

## ğŸ“– Uso

1. **Accede** a http://localhost:3000
2. **Arrastra** un archivo de audio o haz clic para seleccionar
3. **Configura** las opciones:
   - **Modelo**: Elige entre velocidad y calidad
   - **Idioma**: DetecciÃ³n automÃ¡tica o manual
   - **Tarea**: Transcribir o traducir al inglÃ©s
4. **Haz clic** en "Transcribir Audio"
5. **Espera** el procesamiento
6. **Copia** o **descarga** el resultado

## ğŸ¯ Modelos Disponibles

| Modelo | ParÃ¡metros | VRAM  | Velocidad | Recomendado para    |
| ------ | ---------- | ----- | --------- | ------------------- |
| tiny   | 39M        | ~1GB  | ~10x      | âš¡ Pruebas rÃ¡pidas  |
| base   | 74M        | ~1GB  | ~7x       | âš–ï¸ Uso general      |
| small  | 244M       | ~2GB  | ~4x       | ğŸ¯ Buena calidad    |
| medium | 769M       | ~5GB  | ~2x       | ğŸ”¥ Alta calidad     |
| large  | 1550M      | ~10GB | 1x        | â­ MÃ¡xima calidad   |
| turbo  | 809M       | ~6GB  | ~8x       | ğŸš€ RÃ¡pido + calidad |

## ğŸ“ Estructura del Proyecto

```
transcriptor/
â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # AplicaciÃ³n principal
â”‚   â”‚   â”œâ”€â”€ routers/        # Endpoints de API
â”‚   â”‚   â”œâ”€â”€ models/         # Modelos de datos
â”‚   â”‚   â””â”€â”€ utils/          # Servicios Whisper
â”‚   â”œâ”€â”€ requirements.txt    # Dependencias Python
â”‚   â”œâ”€â”€ .env               # Variables de entorno
â”‚   â””â”€â”€ run.py             # Script de inicio
â”œâ”€â”€ frontend/               # AplicaciÃ³n Next.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # PÃ¡ginas Next.js 15
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes React
â”‚   â”‚   â”œâ”€â”€ services/      # Servicios API
â”‚   â”‚   â””â”€â”€ types/         # Tipos TypeScript
â”‚   â”œâ”€â”€ package.json       # Dependencias Node
â”‚   â””â”€â”€ .env.local         # Variables de entorno
â””â”€â”€ README.md              # Este archivo
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

**Backend (.env):**

```env
HOST=0.0.0.0
PORT=8000
DEBUG=True
UPLOAD_DIR=uploads
MAX_FILE_SIZE=100
DEFAULT_MODEL=base
```

**Frontend (.env.local):**

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "FFmpeg not found"

- Instala FFmpeg y asegÃºrate de que estÃ© en el PATH

### Error: "Module not found"

- Activa el entorno virtual del backend
- Instala dependencias: `pip install -r requirements.txt`

### Error: "Cannot connect to backend"

- Verifica que el backend estÃ© corriendo en puerto 8000
- Revisa la variable NEXT_PUBLIC_API_URL

### TranscripciÃ³n lenta

- Usa modelos mÃ¡s pequeÃ±os (tiny, base)
- Verifica que tengas GPU disponible para modelos grandes

## ğŸ› ï¸ Desarrollo

### Comandos Ãºtiles

```bash
# Backend
python run.py              # Iniciar servidor
pip install -r requirements.txt  # Instalar dependencias

# Frontend
npm run dev                # Desarrollo
npm run build              # Construir
npm run lint               # Linting
```

## ğŸ“ Licencia

MIT License - Uso libre para proyectos educativos y comerciales.

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!

1. Fork el proyecto
2. Crea una branch (`git checkout -b feature/nueva-caracteristica`)
3. Commit tus cambios (`git commit -am 'Agregar nueva caracterÃ­stica'`)
4. Push a la branch (`git push origin feature/nueva-caracteristica`)
5. Crea un Pull Request

## ğŸ“§ Soporte

Si tienes problemas o preguntas, puedes:

- Crear un issue en el repositorio
- Revisar la documentaciÃ³n de Whisper: https://github.com/openai/whisper
- Consultar la documentaciÃ³n de FastAPI: https://fastapi.tiangolo.com/
- Revisar la documentaciÃ³n de Next.js: https://nextjs.org/docs

---

**Â¿Te resultÃ³ Ãºtil transcriptor?** â­ Dale una estrella al proyecto y compÃ¡rtelo con otros estudiantes y profesionales que puedan necesitarlo.

**Creado con â¤ï¸ para hacer la transcripciÃ³n de audio accesible para todos.**
