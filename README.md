# üéôÔ∏è transcriptor

**Transcriptor de audio a texto gratuito usando OpenAI Whisper**

Una aplicaci√≥n web completa que permite transcribir archivos de audio a texto de forma gratuita, perfecta para estudiantes, investigadores y profesionales que necesiten convertir grabaciones de reuniones, conferencias o entrevistas a texto.

## üöÄ Caracter√≠sticas

- ‚úÖ **Transcripci√≥n precisa** con modelos Whisper de OpenAI
- ‚úÖ **M√∫ltiples formatos** de audio soportados (MP3, WAV, FLAC, M4A, OGG, WMA, AAC)
- ‚úÖ **Interfaz drag & drop** intuitiva y moderna
- ‚úÖ **9 modelos diferentes** para equilibrar velocidad y calidad (tiny ‚Üí turbo)
- ‚úÖ **Detecci√≥n autom√°tica** de idioma
- ‚úÖ **Traducci√≥n** al ingl√©s disponible
- ‚úÖ **Cancelaci√≥n en tiempo real** de transcripciones en proceso
- ‚úÖ **Tiempos estimados** sin l√≠mites de timeout
- ‚úÖ **Modelos pre-instalados** para despliegue r√°pido
- ‚úÖ **Descarga de resultados** en texto plano
- ‚úÖ **Segmentos detallados** con timestamps
- ‚úÖ **Totalmente gratuito** y open source

## üì¶ Descarga Ejecutable Windows

**¬øQuieres usar la aplicaci√≥n sin configurar nada?**

üì• **[Descargar Transcriptor Audio a Texto (3.3 GB)](https://drive.google.com/file/d/1lx9FGWMUmo_9QK_mcH1eVZz2e6d63JfH/view?usp=drive_link)**

### ‚ú® Caracter√≠sticas del ejecutable:
- ‚úÖ **Todo incluido**: Python + Whisper + Dependencias
- ‚úÖ **Sin instalaci√≥n**: Solo extraer y ejecutar
- ‚úÖ **Portable**: Funciona en cualquier Windows
- ‚úÖ **9 modelos IA**: Todos los modelos Whisper pre-instalados
- ‚úÖ **Tama√±o**: ~3.3 GB (todos los modelos incluidos)

### üöÄ Instrucciones de uso:
1. **Haz clic** en el enlace de descarga de Google Drive
2. **Descarga** el archivo `win-unpacked.rar` (3.3 GB)
3. **Extrae** el contenido en cualquier carpeta
4. **Ejecuta** `Transcriptor Audio a Texto.exe`
5. ¬°**Listo**! La aplicaci√≥n se abrir√° autom√°ticamente

> **Nota**: Este ejecutable incluye todos los modelos de IA para que funcione sin conexi√≥n a internet durante la transcripci√≥n.

## üèóÔ∏è Arquitectura

- **Frontend**: Next.js 15 + React 18 + TypeScript + Tailwind CSS
- **Backend**: FastAPI + Python + OpenAI Whisper
- **Transcripci√≥n**: OpenAI Whisper (modelos tiny, base, small, medium, large, turbo)

## üìã Prerrequisitos

- **Node.js** 18 o superior
- **Python** 3.8 o superior
- **FFmpeg** (para procesamiento de audio)

### Instalar FFmpeg en Windows:

```powershell
# Con Chocolatey
choco install ffmpeg

# Con Scoop
scoop install ffmpeg
```

## üöÄ Instalaci√≥n Completa

### 1. Clonar el proyecto

```bash
cd c:\Users\tu_usuario\tu_carpeta
# El proyecto ya est√° en transcriptor/
```

### 2. Configurar Backend

```bash
cd c:\backend

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual (Windows)
.\venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Iniciar servidor
python run.py
```

El backend estar√° disponible en: http://localhost:8000

### 3. Configurar Frontend

```bash
cd c:\frontend

# Instalar dependencias
npm install

# Iniciar aplicaci√≥n
npm run dev
```

La aplicaci√≥n estar√° disponible en: http://localhost:3000

## üìñ Uso

1. **Accede** a http://localhost:3000
2. **Arrastra** un archivo de audio o haz clic para seleccionar
3. **Configura** las opciones:
   - **Modelo**: Elige entre velocidad y calidad
   - **Idioma**: Detecci√≥n autom√°tica o manual
   - **Tarea**: Transcribir o traducir al ingl√©s
4. **Haz clic** en "Transcribir Audio"
5. **Espera** el procesamiento
6. **Copia** o **descarga** el resultado

## üéØ Modelos Disponibles

| Modelo    | Nivel | Tiempo Estimado | Par√°metros | Recomendado para              |
|-----------|-------|----------------|------------|-------------------------------|
| tiny      | 1     | ~3 min         | 39M        | ‚ö° Pruebas r√°pidas           |
| base      | 2     | ~5 min         | 74M        | ‚öñÔ∏è Uso general (recomendado) |
| small     | 3     | ~8 min         | 244M       | üéØ Buena calidad             |
| medium    | 4     | ~12 min        | 769M       | üî• Alta calidad              |
| large-v1  | 5     | ~16 min        | 1550M      | ‚≠ê M√°xima calidad v1         |
| large-v2  | 6     | ~18 min        | 1550M      | ‚≠ê M√°xima calidad v2         |
| large-v3  | 7     | ~20 min        | 1550M      | ‚≠ê M√°xima calidad v3         |
| large     | 8     | ~22 min        | 1550M      | ‚≠ê M√°xima calidad (√∫ltima)   |
| turbo     | 9     | ~10 min        | 809M       | üöÄ R√°pido + calidad         |

## üìÅ Estructura del Proyecto

```
transcriptor/
‚îú‚îÄ‚îÄ backend/                 # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py         # Aplicaci√≥n principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/        # Endpoints de API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/         # Modelos de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Servicios Whisper
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ .env               # Variables de entorno
‚îÇ   ‚îî‚îÄ‚îÄ run.py             # Script de inicio
‚îú‚îÄ‚îÄ frontend/               # Aplicaci√≥n Next.js
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/           # P√°ginas Next.js 15
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/    # Componentes React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/      # Servicios API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/         # Tipos TypeScript
‚îÇ   ‚îú‚îÄ‚îÄ package.json       # Dependencias Node
‚îÇ   ‚îî‚îÄ‚îÄ .env.local         # Variables de entorno
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

## üîß Configuraci√≥n Avanzada

### Variables de Entorno

**Backend (.env):**

```env
HOST=0.0.0.0
PORT=8000
DEBUG=True
UPLOAD_DIR=uploads
MAX_FILE_SIZE=100
DEFAULT_MODEL=base
```

**Frontend (.env.local):**

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## üêõ Soluci√≥n de Problemas

### Error: "FFmpeg not found"

- Instala FFmpeg y aseg√∫rate de que est√© en el PATH

### Error: "Module not found"

- Activa el entorno virtual del backend
- Instala dependencias: `pip install -r requirements.txt`

### Error: "Cannot connect to backend"

- Verifica que el backend est√© corriendo en puerto 8000
- Revisa la variable NEXT_PUBLIC_API_URL

### Transcripci√≥n lenta

- Usa modelos m√°s peque√±os (tiny, base)
- Verifica que tengas GPU disponible para modelos grandes

## üõ†Ô∏è Desarrollo

### Comandos √∫tiles

```bash
# Backend
python run.py              # Iniciar servidor
pip install -r requirements.txt  # Instalar dependencias

# Frontend
npm run dev                # Desarrollo
npm run build              # Construir
npm run lint               # Linting
```

## üöÄ Despliegue en Producci√≥n

> **‚ö†Ô∏è Importante**: Los modelos de Whisper son muy pesados (hasta 3+ GB) para servicios gratuitos. **Recomendamos usar el [ejecutable Windows](#-descarga-ejecutable-windows)** para la mejor experiencia.

### Nuevas funcionalidades implementadas:

#### ‚úÖ Cancelaci√≥n de Transcripci√≥n
- Bot√≥n "X" para cancelar transcripci√≥n en tiempo real
- API endpoint para cancelaci√≥n (`DELETE /api/v1/transcribe/{task_id}`)
- Manejo seguro de tareas as√≠ncronas

#### ‚úÖ Modelos Pre-instalados
- Todos los modelos Whisper descargados durante el build
- Sin esperas de descarga para usuarios finales
- Configuraci√≥n autom√°tica seg√∫n entorno

#### ‚úÖ Tiempos Estimados (Sin Timeouts)
- Informaci√≥n de tiempo estimado por modelo
- Sin l√≠mites que interrumpan la transcripci√≥n
- Proceso contin√∫a hasta completarse

### Backend (Render/Railway/Fly.io)

**Variables de entorno requeridas:**
```bash
ENVIRONMENT=production  # Activa pre-carga de todos los modelos
ALLOWED_ORIGINS=https://tu-frontend.vercel.app
PORT=8000
DEBUG=False
```

**Pasos para desplegar:**

1. **Render/Railway:** 
   - Conecta tu repositorio GitHub
   - Configura las variables de entorno
   - El servicio ejecutar√° autom√°ticamente `python run.py`

2. **Script de pre-instalaci√≥n:**
   ```bash
   # En tu servidor, ejecuta una sola vez:
   python preinstall_models.py
   ```

   Esto descarga todos los modelos Whisper y los deja listos para usar.

**Archivo de configuraci√≥n para servicios (render.yaml):**
```yaml
services:
  - type: web
    name: transcriptor-backend
    env: python
    buildCommand: "pip install -r requirements.txt && python preinstall_models.py"
    startCommand: "python run.py"
    envVars:
      - key: ENVIRONMENT
        value: production
```

### Frontend (Vercel/Netlify)

**Variables de entorno:**
```bash
NEXT_PUBLIC_API_URL=https://tu-backend.render.com
```

### Modelos y tiempos estimados:

| Modelo | Nivel | Tiempo Estimado | Descripci√≥n |
|--------|-------|----------------|-------------|
| tiny | 1 | ~3 min | M√°s r√°pido, menos preciso |
| base | 2 | ~5 min | Equilibrado (recomendado) |
| small | 3 | ~8 min | Buena calidad |
| medium | 4 | ~12 min | Alta calidad |
| large-v1 | 5 | ~16 min | M√°xima calidad v1 |
| large-v2 | 6 | ~18 min | M√°xima calidad v2 |
| large-v3 | 7 | ~20 min | M√°xima calidad v3 |
| large | 8 | ~22 min | M√°xima calidad (√∫ltima) |
| turbo | 9 | ~10 min | Optimizado, r√°pido |

### Servicios de despliegue recomendados:

**Backend:**
- **Render**: Deploy autom√°tico desde GitHub
- **Railway**: F√°cil configuraci√≥n
- **Fly.io**: Alta performance

**Frontend:**
- **Vercel**: Optimizado para Next.js
- **Netlify**: Simple y r√°pido
- **Cloudflare Pages**: CDN global

## üìù Licencia

MIT License - Uso libre para proyectos educativos y comerciales.

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas!

1. Fork el proyecto
2. Crea una branch (`git checkout -b feature/nueva-caracteristica`)
3. Commit tus cambios (`git commit -am 'Agregar nueva caracter√≠stica'`)
4. Push a la branch (`git push origin feature/nueva-caracteristica`)
5. Crea un Pull Request

## üìß Soporte

Si tienes problemas o preguntas, puedes:

- Crear un issue en el repositorio
- Revisar la documentaci√≥n de Whisper: https://github.com/openai/whisper
- Consultar la documentaci√≥n de FastAPI: https://fastapi.tiangolo.com/
- Revisar la documentaci√≥n de Next.js: https://nextjs.org/docs

---

**¬øTe result√≥ √∫til transcriptor?** ‚≠ê Dale una estrella al proyecto y comp√°rtelo con otros estudiantes y profesionales que puedan necesitarlo.

**Creado con ‚ù§Ô∏è para hacer la transcripci√≥n de audio accesible para todos.**
